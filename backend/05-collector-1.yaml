apiVersion: opentelemetry.io/v1alpha1
kind: OpenTelemetryCollector
metadata:
  name: otel
  namespace: observability-backend
spec:
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.94.0
  mode: deployment
  replicas: 1
  ports:
    - port: 8888
      protocol: TCP
      name: metrics
  config: |
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
    
    processors:   
      tail_sampling:
        decision_wait: 10s # time to wait before making a sampling decision
        num_traces: 100 # number of traces to be kept in memory
        expected_new_traces_per_sec: 10 # expected rate of new traces per second
        policies:
          - name: keep-errors
            type: status_code
            status_code: {status_codes: [ERROR]}
          - name: keep-slow-traces
            type: latency
            latency: {threshold_ms: 500}
          - name: randomized-policy
            type: probabilistic
            probabilistic: {sampling_percentage: 10}            

    exporters:
      otlp/traces:
        endpoint: jaeger-collector:4317
        tls:
          insecure: true
      
      otlphttp/metrics:
        endpoint: http://prometheus.observability-backend.svc.cluster.local:80/api/v1/otlp/
        tls:
          insecure: true
      
      debug:
        verbosity: detailed

    service:
      pipelines:
        traces:
          receivers: [otlp]
          processors: [tail_sampling]
          exporters: [otlp/traces]
        metrics:
          receivers: [otlp]
          exporters: [otlphttp/metrics]
        logs:
          receivers: [otlp]
          exporters: [debug]
